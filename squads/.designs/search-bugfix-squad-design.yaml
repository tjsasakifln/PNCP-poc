# Squad Design Blueprint: Search & Export Bugfix Squad
# Generated by: squad-creator agent
# Date: 2026-02-10
# Purpose: Diagnose and fix critical bugs in search (2 results) and Google Sheets export (HTTP 404)

metadata:
  name: search-bugfix-squad
  title: "Equipe de Correção de Busca e Exportação"
  version: "1.0.0"
  description: "Squad especializado em diagnóstico e correção de bugs críticos no sistema de busca e exportação do SmartLic"
  owner: "tiago.sasaki@synkra.dev"
  tags: ["bugfix", "search", "export", "critical", "p0"]
  created_at: "2026-02-10T21:30:00Z"

problem_statement: |
  PROBLEMA 1 (P0): Busca retornando apenas 2 resultados
  - Usuário selecionou: todos os estados, todas esferas, todas modalidades
  - Período: 01/jan/2026 - 10/fev/2026 (41 dias)
  - Resultado esperado: centenas/milhares de licitações
  - Resultado obtido: apenas 2 licitações

  PROBLEMA 2 (P0): Exportação para Google Sheets falha com HTTP 404
  - Usuário tenta exportar resultados
  - Erro: "Falha ao exportar para Google Sheets - Erro HTTP 404"
  - Impede uso de feature premium

root_cause_analysis:
  search_bug:
    identified_issues:
      - name: "Limite de paginação muito baixo"
        file: "backend/pncp_client.py"
        line: 461
        code: "max_pages: int = 50"
        impact: "Limita busca a 1000 registros (50 pages × 20 items) por UF+modalidade"
        severity: "CRITICAL"
        explanation: |
          Com 27 UFs e 8 modalidades (Lei 14.133), isso deveria gerar 216 combinações.
          Porém, se houver timeout ou erro em alguma combinação, resultados são perdidos.

      - name: "Possível falha na paralelização de UFs"
        file: "backend/main.py"
        line: 1309
        code: "buscar_todas_ufs_paralelo"
        impact: "Se paralelização falhar silenciosamente, apenas 1-2 UFs são processadas"
        severity: "HIGH"

      - name: "Modalidades padrão podem estar incorretas"
        file: "backend/config.py"
        code: "DEFAULT_MODALIDADES"
        impact: "Se frontend passa None, backend usa padrão que pode estar desatualizado"
        severity: "MEDIUM"

    recommended_diagnostics:
      - "Adicionar logging detalhado de quantos UFs/modalidades foram processados"
      - "Verificar se buscar_todas_ufs_paralelo está retornando corretamente"
      - "Testar busca com 1 UF apenas para validar se paginação funciona"
      - "Verificar logs do backend para exceptions silenciosas"
      - "Aumentar max_pages para 200+ e adicionar warning se limite for atingido"

  export_bug:
    identified_issues:
      - name: "Rota registrada mas endpoint pode estar incorreto"
        file: "backend/main.py"
        line: 99
        code: "app.include_router(export_sheets_router)"
        status: "✓ Rota está registrada"

      - name: "Prefixo da rota pode causar conflito"
        file: "backend/routes/export_sheets.py"
        line: 31
        code: 'router = APIRouter(prefix="/api/export")'
        expected_url: "/api/export/google-sheets"
        actual_call: "/api/export/google-sheets (linha 76 do frontend)"
        status: "URLs parecem corretas"

      - name: "Possível falha de autenticação antes de chegar na rota"
        file: "backend/auth.py"
        code: "require_auth dependency"
        impact: "Se autenticação falhar com 401, frontend trata. Mas 404 indica rota não existe"
        severity: "HIGH"

    recommended_diagnostics:
      - "Verificar se FastAPI está servindo /api/export/google-sheets via curl ou Postman"
      - "Checar se há middleware bloqueando a rota"
      - "Verificar se backend está rodando e saudável"
      - "Inspecionar network tab do navegador para ver URL exata sendo chamada"
      - "Testar rota diretamente via OpenAPI docs (/docs)"

agents:
  - id: "lead-investigator"
    name: "Lead Bug Investigator"
    role: "diagnostics-lead"
    expertise: ["debugging", "root-cause-analysis", "logging", "backend-systems"]
    responsibilities:
      - "Coordenar investigação dos 2 bugs"
      - "Analisar logs do backend e frontend"
      - "Reproduzir bugs em ambiente controlado"
      - "Documentar findings e criar relatório técnico"
    tools: ["logs-analyzer", "debugger", "network-inspector"]

  - id: "search-specialist"
    name: "Search System Specialist"
    role: "search-expert"
    expertise: ["pncp-api", "pagination", "parallel-fetching", "filtering"]
    responsibilities:
      - "Investigar bug de busca retornando 2 resultados"
      - "Analisar lógica de paginação e paralelização"
      - "Verificar filtros sendo aplicados corretamente"
      - "Propor correção e validar com testes"
    dependencies: ["lead-investigator"]

  - id: "export-specialist"
    name: "Export & API Specialist"
    role: "api-expert"
    expertise: ["fastapi", "routes", "middleware", "http-debugging"]
    responsibilities:
      - "Investigar erro HTTP 404 em exportação"
      - "Verificar registro de rotas no FastAPI"
      - "Testar endpoint diretamente"
      - "Propor correção e validar"
    dependencies: ["lead-investigator"]

  - id: "qa-validator"
    name: "QA Validator"
    role: "quality-assurance"
    expertise: ["testing", "regression-testing", "e2e-testing"]
    responsibilities:
      - "Criar testes de regressão para ambos bugs"
      - "Validar correções em ambiente staging"
      - "Executar testes E2E de busca e exportação"
      - "Sign-off final antes de deploy"
    dependencies: ["search-specialist", "export-specialist"]

tasks:
  # FASE 1: DIAGNÓSTICO (30 min)
  - id: "diagnose-search-bug"
    title: "Diagnosticar bug de busca com 2 resultados"
    assigned_to: "search-specialist"
    priority: "P0"
    estimated_time: "20 min"
    acceptance_criteria:
      - "Identificar causa raiz exata (paginação? paralelização? filtros?)"
      - "Reproduzir bug em ambiente local"
      - "Documentar findings com evidências (logs, screenshots)"
      - "Propor solução técnica com code snippet"
    steps:
      - "Adicionar logging detalhado em buscar_todas_ufs_paralelo"
      - "Executar busca com mesmos parâmetros do usuário"
      - "Verificar quantos UFs/modalidades foram processados vs esperado"
      - "Checar se max_pages=50 está sendo atingido"
      - "Testar com max_pages=200 para confirmar hipótese"

  - id: "diagnose-export-bug"
    title: "Diagnosticar erro HTTP 404 em exportação"
    assigned_to: "export-specialist"
    priority: "P0"
    estimated_time: "15 min"
    acceptance_criteria:
      - "Confirmar se rota /api/export/google-sheets está acessível"
      - "Identificar causa raiz exata do 404"
      - "Reproduzir erro"
      - "Propor solução"
    steps:
      - "Verificar backend está rodando: curl http://localhost:8000/health"
      - "Testar rota diretamente: curl -X POST http://localhost:8000/api/export/google-sheets"
      - "Inspecionar /docs para ver se rota aparece na OpenAPI spec"
      - "Verificar logs do FastAPI durante startup"
      - "Checar se CORS ou middleware está bloqueando"

  # FASE 2: CORREÇÃO (45 min)
  - id: "fix-search-bug"
    title: "Implementar correção para bug de busca"
    assigned_to: "search-specialist"
    priority: "P0"
    estimated_time: "30 min"
    dependencies: ["diagnose-search-bug"]
    acceptance_criteria:
      - "Busca com filtros amplos retorna centenas/milhares de resultados"
      - "Paginação funciona corretamente sem limite artificial"
      - "Logs mostram progresso detalhado de UFs/modalidades"
      - "Performance não degradou significativamente"
    technical_approach:
      - "Aumentar max_pages de 50 para 500 (10.000 registros por UF+modalidade)"
      - "Adicionar warning log se max_pages for atingido"
      - "Adicionar contador de UFs/modalidades processadas com sucesso"
      - "Melhorar error handling em buscar_todas_ufs_paralelo"

  - id: "fix-export-bug"
    title: "Implementar correção para bug de exportação"
    assigned_to: "export-specialist"
    priority: "P0"
    estimated_time: "20 min"
    dependencies: ["diagnose-export-bug"]
    acceptance_criteria:
      - "Exportação para Google Sheets funciona sem erros"
      - "Resposta HTTP 200 com spreadsheet_url válida"
      - "Planilha abre corretamente no Google Sheets"
    technical_approach:
      - "Based on diagnosis findings"
      - "Likely: Verificar se backend iniciou completamente antes de frontend fazer request"
      - "Ou: Corrigir prefixo de rota se houver conflito"

  # FASE 3: VALIDAÇÃO (30 min)
  - id: "test-search-fix"
    title: "Criar e executar testes para correção de busca"
    assigned_to: "qa-validator"
    priority: "P0"
    estimated_time: "20 min"
    dependencies: ["fix-search-bug"]
    acceptance_criteria:
      - "Teste unitário para paginação com max_pages alto"
      - "Teste E2E de busca com filtros amplos"
      - "Teste de regressão para garantir que filtros existentes ainda funcionam"
      - "Performance test: busca com 27 UFs completa em < 4 min"
    test_cases:
      - name: "Busca ampla (todos estados, todas modalidades)"
        expected: "> 100 resultados"
      - name: "Busca com 1 UF, 1 modalidade"
        expected: "Paginação funciona até o fim"
      - name: "Busca com período longo (6 meses)"
        expected: "Date chunking funciona corretamente"

  - id: "test-export-fix"
    title: "Criar e executar testes para correção de exportação"
    assigned_to: "qa-validator"
    priority: "P0"
    estimated_time: "15 min"
    dependencies: ["fix-export-bug"]
    acceptance_criteria:
      - "Teste E2E de exportação completa"
      - "Teste de autenticação OAuth funciona"
      - "Teste de error handling (quota excedida, token revoked)"
    test_cases:
      - name: "Exportação com autenticação válida"
        expected: "HTTP 200, spreadsheet_url válida"
      - name: "Exportação sem autenticação"
        expected: "HTTP 401, redirect para OAuth"
      - name: "Exportação com > 1000 linhas"
        expected: "Todas linhas exportadas corretamente"

workflows:
  - id: "emergency-bugfix-workflow"
    name: "Emergency Bugfix Workflow (P0)"
    description: "Workflow acelerado para correção de bugs críticos em produção"
    estimated_duration: "105 min (1h45min)"
    phases:
      - name: "Diagnóstico Rápido"
        duration: "30 min"
        tasks: ["diagnose-search-bug", "diagnose-export-bug"]
        deliverables:
          - "Root cause analysis document"
          - "Reproduction steps"
          - "Proposed technical solution"

      - name: "Correção Simultânea"
        duration: "45 min"
        tasks: ["fix-search-bug", "fix-export-bug"]
        deliverables:
          - "Code fixes committed"
          - "Migration scripts (if needed)"
          - "Updated documentation"

      - name: "Validação e Deploy"
        duration: "30 min"
        tasks: ["test-search-fix", "test-export-fix"]
        deliverables:
          - "Test reports"
          - "Staging deployment validated"
          - "Production deployment ready"

templates:
  - id: "bug-diagnosis-report"
    name: "Bug Diagnosis Report Template"
    description: "Template estruturado para documentar diagnóstico de bugs"
    file: "bug-diagnosis-report.md"

  - id: "hotfix-pr-template"
    name: "Hotfix Pull Request Template"
    description: "Template para PRs de hotfix com validações obrigatórias"
    file: "hotfix-pr-template.md"

checklists:
  - id: "pre-deploy-checklist"
    name: "Pre-Deployment Checklist (Hotfix)"
    description: "Checklist obrigatório antes de deploy de hotfix em produção"
    items:
      - "✅ Root cause identificada e documentada"
      - "✅ Correção testada localmente"
      - "✅ Testes de regressão passaram"
      - "✅ Code review aprovado por senior engineer"
      - "✅ Staging deployment validado"
      - "✅ Rollback plan documentado"
      - "✅ Monitoring alerts configurados"
      - "✅ User communication prepared (if customer-facing)"

tools:
  - id: "logs-analyzer"
    name: "Logs Analyzer Script"
    description: "Script para extrair e analisar logs relevantes do backend"
    command: "python scripts/analyze_logs.py --search-id <id>"

  - id: "pncp-api-tester"
    name: "PNCP API Direct Tester"
    description: "Ferramenta para testar API PNCP diretamente"
    command: "python scripts/test_pncp_api.py --uf SP --modalidade 1"

data:
  test_datasets:
    - name: "wide-search-params"
      description: "Parâmetros de busca ampla para reproduzir bug"
      file: "test-data/wide-search-params.json"
      content:
        ufs: ["AC","AL","AP","AM","BA","CE","DF","ES","GO","MA","MT","MS","MG","PA","PB","PR","PE","PI","RJ","RN","RS","RO","RR","SC","SP","SE","TO"]
        esferas: ["estadual", "municipal", "federal"]
        modalidades: [1, 2, 3, 4, 5, 6, 7, 8]
        data_inicial: "2026-01-01"
        data_final: "2026-02-10"
        setor_id: "engenharia_construcao"

config:
  coding_standards:
    - "Use Python type hints em todas funções"
    - "Adicione logging detalhado para debugging"
    - "Docstrings obrigatórios para funções públicas"
    - "Error handling robusto com mensagens user-friendly"

  tech_stack:
    backend:
      - "FastAPI"
      - "Python 3.12"
      - "httpx/requests"
      - "asyncio"
    frontend:
      - "Next.js 14"
      - "TypeScript"
      - "React 18"
      - "TailwindCSS"

  testing_strategy:
    - "Unit tests para lógica de paginação"
    - "Integration tests para rotas FastAPI"
    - "E2E tests para fluxos completos (Playwright)"
    - "Performance tests com load testing"

success_metrics:
  search_fix:
    - metric: "Search Success Rate"
      target: "> 99%"
      measurement: "Percentage of searches returning expected results"

    - metric: "Search Coverage"
      target: "100% of UFs+modalidades processed"
      measurement: "Count of successfully fetched combinations"

    - metric: "Search Performance"
      target: "< 4 min for 27 UFs"
      measurement: "End-to-end search time"

  export_fix:
    - metric: "Export Success Rate"
      target: "> 99%"
      measurement: "Percentage of exports completing successfully"

    - metric: "Export Latency"
      target: "< 10s for 1000 rows"
      measurement: "Time from request to spreadsheet_url returned"
